<div align="center">

# ä¸­æ–‡å¯¹è¯æ¨¡å‹0.2B Small Chinese Chat LM 0.2B  

ä¸­æ–‡  | [English](./README.en.md)  

</div>
 
# ä¸€ã€ä»‹ç» 
SCCLMé¡¹ç›®çš„ç›®æ ‡æ˜¯ä»å¤´å¼€å§‹è®­ç»ƒä¸€ä¸ªä¸­æ–‡å¯¹è¯å°æ¨¡å‹ã€‚æ•´ç†ç”Ÿæˆå¼è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®æ¸…æ´—ã€tokenizerè®­ç»ƒã€æ¨¡å‹é¢„è®­ç»ƒã€SFTæŒ‡ä»¤å¾®è°ƒã€RLHFä¼˜åŒ–ç­‰ã€‚ 

SCCLMä¸ºä¸­æ–‡å¯¹è¯å°æ¨¡å‹ï¼Œæ¨¡å‹å‚æ•°åªæœ‰0.2Bï¼ˆç®—å…±äº«æƒé‡çº¦210Mï¼‰ï¼Œå¯ä»¥åœ¨æœ€ä½4GBæ˜¾å­˜çš„æœºå™¨è¿›è¡Œé¢„è®­ç»ƒï¼ˆ`batch_size=1`ï¼Œ`fp16`æˆ–è€…` bf16`ï¼‰ï¼Œ`float16`åŠ è½½ã€æ¨ç†æœ€å°‘åªéœ€è¦512MBæ˜¾å­˜ã€‚ 


- å…¬å¼€æ‰€æœ‰é¢„è®­ç»ƒã€SFTæŒ‡ä»¤å¾®è°ƒã€DPOåå¥½ä¼˜åŒ–æ•°æ®é›†æ¥æºã€‚
- ä½¿ç”¨`Huggingface`NLPæ¡†æ¶ï¼ŒåŒ…æ‹¬`transformers`ã€`accelerate`ã€`trl`ã€`peft`ç­‰ã€‚
- è‡ªå®ç°`trainer`ï¼Œæ”¯æŒå•æœºå•å¡è¿›è¡Œé¢„è®­ç»ƒã€SFTå¾®è°ƒã€‚è®­ç»ƒè¿‡ç¨‹ä¸­æ”¯æŒåœ¨ä»»æ„ä½ç½®åœæ­¢ï¼ŒåŠåœ¨ä»»æ„ä½ç½®ç»§ç»­è®­ç»ƒã€‚
- é¢„è®­ç»ƒï¼šæ•´åˆä¸ºç«¯åˆ°ç«¯çš„`Text-to-Text`é¢„è®­ç»ƒï¼Œé`mask`æ©ç é¢„æµ‹é¢„è®­ç»ƒã€‚
    - å¼€æºæ‰€æœ‰æ•°æ®æ¸…æ´—ã€æ•°æ®é›†æ„é€ ã€æ•°æ®é›†åŠ è½½ç­‰æµç¨‹ï¼›
    - `huggingface tokenizers`çš„tokenizerè®­ç»ƒï¼›
    - é¢„è®­ç»ƒæ”¯æŒä»»æ„ä½ç½®æ–­ç‚¹ï¼Œå¯ä»æ–­ç‚¹å¤„ç»§ç»­è®­ç»ƒ;
    - å¤§æ•°æ®é›†ï¼ˆGBçº§åˆ«ï¼‰æµå¼åŠ è½½ã€æ”¯æŒç¼“å†²åŒºæ•°æ®æ‰“ä¹±ï¼Œä¸åˆ©ç”¨å†…å­˜ã€ç¡¬ç›˜ä½œä¸ºç¼“å­˜ï¼Œæœ‰æ•ˆå‡å°‘å†…å­˜ã€ç£ç›˜å ç”¨ã€‚é…ç½®`batch_size=1, max_len=320`ä¸‹ï¼Œæœ€ä½æ”¯æŒåœ¨16GBå†…å­˜+4GBæ˜¾å­˜çš„æœºå™¨ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼›
    - è®­ç»ƒæ—¥å¿—è®°å½•ã€‚
- SFTå¾®è°ƒï¼šå¼€æºSFTæ•°æ®é›†åŠæ•°æ®å¤„ç†è¿‡ç¨‹ã€‚
    - å®ç°`trainer`æ”¯æŒpromptæŒ‡ä»¤å¾®è°ƒï¼Œ æ”¯æŒä»»æ„æ–­ç‚¹ç»§ç»­è®­ç»ƒï¼›
    - æ”¯æŒ`Huggingface trainer`çš„`sequence to sequence`å¾®è°ƒï¼›
    - æ”¯æŒä¼ ç»Ÿçš„ä½å­¦ä¹ ç‡ï¼Œåªè®­ç»ƒdecoderå±‚çš„å¾®è°ƒã€‚
- åå¥½ä¼˜åŒ–ï¼šä½¿ç”¨DPOè¿›è¡Œå…¨é‡åå¥½ä¼˜åŒ–ã€‚
    - æ”¯æŒä½¿ç”¨`peft lora`è¿›è¡Œåå¥½ä¼˜åŒ–ï¼›
    - æ”¯æŒæ¨¡å‹åˆå¹¶ï¼Œå¯å°†`Lora adapter`åˆå¹¶åˆ°åŸå§‹æ¨¡å‹ä¸­ã€‚
- æ”¯æŒä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒï¼š[finetune_examples](./finetune_examples/info_extract/)ç»™å‡º**ä¸‰å…ƒç»„ä¿¡æ¯æŠ½å–ä»»åŠ¡**çš„å¾®è°ƒç¤ºä¾‹ï¼Œå¾®è°ƒåçš„æ¨¡å‹å¯¹è¯èƒ½åŠ›ä»åœ¨ã€‚

**æœ€è¿‘æ›´æ–°**

<details close> 
<summary> <b>2024-01-31</b> </summary>
- é¡¹ç›®å¼€æºï¼Œ å¼€æ”¾æ¨¡å‹æƒé‡ä¾›ä¸‹è½½ã€‚ <br/>
</details>


# äºŒã€SCCLM-0.2Bæ¨¡å‹è®­ç»ƒè¿‡ç¨‹ 

## 2.1 æ•°æ®é›†
æ‰€æœ‰æ•°æ®é›†å‡æ¥è‡ªäº’è”ç½‘å…¬å¼€çš„**å•è½®å¯¹è¯**æ•°æ®é›†ï¼Œç»è¿‡æ•°æ®æ¸…æ´—ã€æ ¼å¼åŒ–åä¿å­˜ä¸ºparquetæ–‡ä»¶ã€‚

### 2.1.1 é¢„è®­ç»ƒæ•°æ®é›†
æ•°æ®å¤„ç†è¿‡ç¨‹è§`scripts/make_data.py`ã€‚ä¸»è¦æ•°æ®é›†åŒ…æ‹¬ï¼š 

1. ç¤¾åŒºé—®ç­”jsonç‰ˆwebtext2019zh-å¤§è§„æ¨¡é«˜è´¨é‡æ•°æ®é›†ï¼Œè§ï¼š[nlp_chinese_corpus](https://github.com/brightmart/nlp_chinese_corpus)ã€‚
2. baike_qa2019ç™¾ç§‘ç±»é—®ç­”ï¼Œè§ï¼š[baike_qa2019](https://aistudio.baidu.com/datasetdetail/107726)ã€‚
3. ä¸­å›½åŒ»è¯é¢†åŸŸé—®ç­”æ•°æ®é›†ï¼Œè§ï¼š[Chinese-medical-dialogue-data]https://github.com/Toyhom/Chinese-medical-dialogue-dataã€‚
4. çŸ¥ä¹é—®ç­”æ•°æ®ï¼Œè§ï¼š[Zhihu-KOL]https://huggingface.co/datasets/wangrui6/Zhihu-KOLã€‚
5. belleå¼€æºçš„æŒ‡ä»¤è®­ç»ƒæ•°æ®ï¼Œä»‹ç»ï¼š[BELLE](https://github.com/LianjiaTech/BELLE)ï¼Œä¸‹è½½ï¼š[BelleGroup](https://huggingface.co/BelleGroup)ï¼Œä»…é€‰å–`Belle_open_source_1M`ã€`train_2M_CN`ã€åŠ`train_3.5M_CN`ä¸­éƒ¨åˆ†å›ç­”è¾ƒçŸ­ã€ä¸å«å¤æ‚è¡¨æ ¼ç»“æ„ã€ç¿»è¯‘ä»»åŠ¡ï¼ˆæ²¡åšè‹±æ–‡è¯è¡¨ï¼‰çš„æ•°æ®ï¼Œå…±370ä¸‡è¡Œï¼Œæ¸…æ´—åå‰©ä½™338ä¸‡è¡Œã€‚
6. ç»´åŸºç™¾ç§‘ï¼ˆWikipediaï¼‰è¯æ¡æ•°æ®ï¼Œå°†è¯æ¡æ‹¼å‡‘ä¸ºæç¤ºè¯­ï¼Œç™¾ç§‘çš„å‰`N`ä¸ªè¯ä¸ºå›ç­”ï¼Œä½¿ç”¨`202309`çš„ç™¾ç§‘æ•°æ®ã€‚Wikiä¸‹è½½ï¼š[zhwiki](https://dumps.wikimedia.org/zhwiki/)ï¼Œå°†ä¸‹è½½çš„bz2æ–‡ä»¶è½¬æ¢ä¸ºwiki.txtå‚è€ƒï¼š[WikiExtractor](https://github.com/apertium/WikiExtractor)ã€‚ 

æ•°æ®ç¤ºä¾‹ï¼š
```json
{
    "prompt": "å¯¹äºèŠ±å›­è¡—ï¼Œä½ æœ‰ä»€ä¹ˆäº†è§£æˆ–çœ‹æ³•å—ï¼Ÿ",
    "response": "èŠ±å›­è¡—ï¼ˆæ˜¯é¦™æ¸¯æ²¹å°–æ—ºåŒºçš„ä¸€æ¡å¯Œæœ‰ç‰¹è‰²çš„è¡—é“ï¼Œä½äºä¹é¾™æ—ºè§’ä¸œéƒ¨ï¼ŒåŒ—è‡³ç•Œé™è¡—ï¼Œå—è‡³ç™»æ‰“å£«è¡—ï¼Œä¸é€šèœè¡—åŠæ´—è¡£è¡—ç­‰è¡—é“å¹³è¡Œã€‚ç°æ—¶è¿™æ¡è¡—é“æ˜¯é¦™æ¸¯è‘—åçš„è´­ç‰©åŒºä¹‹ä¸€ã€‚ä½äºäºšçš†è€è¡—ä»¥å—çš„ä¸€æ®µèŠ±å›­è¡—ï¼Œä¹Ÿå°±æ˜¯\"æ³¢é‹è¡—\"æ•´æ¡è¡—çº¦150ç±³é•¿ï¼Œæœ‰50å¤šé—´å”®å–è¿åŠ¨é‹å’Œè¿åŠ¨ç”¨å“çš„åº—èˆ–ã€‚æ—ºè§’é“è‡³å¤ªå­é“è¥¿ä¸€æ®µåˆ™ä¸ºæ’æ¡£åŒºï¼Œå”®å–æˆè¡£ã€è”¬èœå’Œæ°´æœç­‰ã€‚èŠ±å›­è¡—ä¸€å…±åˆ†æˆä¸‰æ®µã€‚æ˜æ¸…æ—¶ä»£ï¼ŒèŠ±å›­è¡—æ˜¯èŠ’è§’æ‘æ ½ç§èŠ±å‰çš„åœ°æ–¹ã€‚æ­¤å¤–ï¼Œæ ¹æ®å†å²ä¸“å®¶éƒ‘å®é¸¿çš„è€ƒè¯ï¼šèŠ±å›­è¡—æ›¾æ˜¯1910å¹´ä»£ä¸œæ–¹æ®·ç´æ‹¿çƒŸå‚çš„èŠ±å›­ã€‚çºµç«æ¡ˆã€‚è‡ª2005å¹´èµ·ï¼ŒèŠ±å›­è¡—ä¸€å¸¦æœ€å°‘å‘ç”Ÿ5å®—çºµç«æ¡ˆï¼Œå½“ä¸­4å®—æ¶‰åŠæ’æ¡£èµ·ç«ã€‚2010å¹´ã€‚2010å¹´12æœˆ6æ—¥ï¼ŒèŠ±å›­è¡—222å·ä¸€ä¸ªå–é‹çš„æ’æ¡£äºå‡Œæ™¨5æ—¶è®¸é¦–å…ˆèµ·ç«ï¼Œæµ“çƒŸæ¶Œå¾€æ—è¾¹ä½å®…å¤§å¦ï¼Œæ¶ˆé˜²æ¥æŠ¥4"
}
```
### 2.1.2 SFTå¾®è°ƒæ•°æ®é›†
SFTå¾®è°ƒå’ŒDPOä¼˜åŒ–æ•°æ®é›†è§ä¸‹æ–‡ã€‚
SFTæ•°æ®é›†å…¨éƒ¨æ¥è‡ª[BELLE](https://github.com/LianjiaTech/BELLE)ã€‚SFTæ•°æ®é›†åˆ†åˆ«ä¸ºï¼š[generated_chat_0.4M](https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M)ã€[train_0.5M_CN](https://huggingface.co/datasets/BelleGroup/train_0.5M_CN)å’Œ[train_2M_CN](https://huggingface.co/datasets/BelleGroup/train_2M_CN)ã€‚

æ•°æ®ç¤ºä¾‹ï¼š
```json
{
    "prompt": "è§£é‡Šä»€ä¹ˆæ˜¯æ¬§æ´²å¯ç¤ºå½•",
    "response": "æ¬§æ´²å¯ç¤ºå½•ï¼ˆThe Book of Revelationï¼‰æ˜¯æ–°çº¦åœ£ç»çš„æœ€åä¸€å·ä¹¦ï¼Œä¹Ÿè¢«ç§°ä¸ºã€Šå¯ç¤ºå½•ã€‹ã€ã€Šé»˜ç¤ºå½•ã€‹æˆ–ã€Šçº¦ç¿°é»˜ç¤ºå½•ã€‹ã€‚è¿™æœ¬ä¹¦ä»å®—æ•™çš„è§’åº¦æè¿°äº†ä¸–ç•Œæœ«æ—¥çš„æ¥ä¸´ï¼Œä»¥åŠä¸Šå¸å¯¹ä¸–ç•Œçš„å®¡åˆ¤å’Œæ‹¯æ•‘ã€‚ ä¹¦ä¸­çš„ä¸»é¢˜åŒ…æ‹¬æ¥ä¸´çš„åŸºç£çš„è£è€€ï¼Œä¸Šå¸å¯¹äººæ€§çš„æƒ©ç½šå’Œæ‹¯æ•‘ï¼Œä»¥åŠé­”é¬¼å’Œé‚ªæ¶åŠ›é‡çš„å­˜åœ¨ã€‚æ¬§æ´²å¯ç¤ºå½•æ˜¯ä¸€ä¸ªå……æ»¡è±¡å¾å’Œæš—ç¤ºçš„æ–‡æœ¬ï¼Œå¯¹äºè§£è¯»å’Œç†è§£æœ‰è®¸å¤šä¸åŒçš„æ–¹æ³•å’Œè§‚ç‚¹ã€‚"
}
```

### 2.1.3 DPOä¼˜åŒ–æ•°æ®é›†
1. å¾®è°ƒçš„`chosen`æ–‡æœ¬æ¥è‡ªæ•°æ®é›†[alpaca-gpt4-data-zh](https://huggingface.co/datasets/c-s-ale/alpaca-gpt4-data-zh)ï¼Œæ‹’ç»æ–‡æœ¬`rejected`æ¥è‡ªSFTå¾®è°ƒ1ä¸ªepochåçš„æ¨¡å‹è¾“å‡º
2. æ•°æ®é›†ï¼š[huozi_rlhf_data_json](https://huggingface.co/datasets/Skepsun/huozi_rlhf_data_json)
3. æ•°æ®é›†ï¼š[rlhf-reward-single-round-trans_chinese](https://huggingface.co/datasets/beyond/rlhf-reward-single-round-trans_chinese)

æ•°æ®ç¤ºä¾‹ï¼š
```json
    {
        "prompt": "ä¸ºç»™å®šçš„äº§å“åˆ›å»ºä¸€ä¸ªåˆ›æ„æ ‡è¯­ã€‚ï¼Œè¾“å…¥ï¼šå¯é‡å¤ä½¿ç”¨çš„æ°´ç“¶ã€‚",
        "chosen": "\"ä¿æŠ¤åœ°çƒï¼Œä»æ‹¥æœ‰å¯é‡å¤ä½¿ç”¨çš„æ°´ç“¶å¼€å§‹ï¼\"",
        "rejected": "\"è®©ä½ çš„æ°´ç“¶æˆä¸ºä½ çš„ç”Ÿæ´»ä¼´ä¾£ï¼Œä½¿ç”¨å¯é‡å¤ä½¿ç”¨çš„æ°´ç“¶ï¼Œè®©ä½ çš„æ°´ç“¶æˆä¸ºä½ çš„ä¼™ä¼´\""
    }
```

## 2.2 æ¨¡å‹
T5æ¨¡å‹ï¼ˆText-to-Text Transfer Transformerï¼‰ï¼Œè¯¦æƒ…è§è®ºæ–‡: [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683)ã€‚

æ¨¡å‹æºç æ¥è‡ªhuggingfaceï¼Œè§ï¼š[T5ForConditionalGeneration](https://github.com/huggingface/transformers/blob/main/src/transformers/models/t5/modeling_t5.py#L1557)ã€‚

æ¨¡å‹é…ç½®è§[model_config.json](https://huggingface.co/charent/ChatLM-mini-Chinese/blob/main/config.json)ï¼Œå®˜æ–¹çš„`T5-base`ï¼š`encoder layer`å’Œ`decoder layer `å‡ä¸ºä¸º12å±‚ï¼Œæœ¬é¡¹ç›®è¿™ä¸¤ä¸ªå‚æ•°ä¿®æ”¹ä¸º10å±‚ã€‚ 

æ¨¡å‹å‚æ•°ï¼š0.2Bã€‚è¯è¡¨å¤§å°ï¼š29298ï¼Œä»…åŒ…å«ä¸­æ–‡å’Œå°‘é‡è‹±æ–‡ã€‚

## 2.3 è®­ç»ƒè¿‡ç¨‹
ç¡¬ä»¶ï¼š
```bash
CPU: 28 vCPU Intel(R) Xeon(R) Gold 6330 CPU @ 2.00GHz
å†…å­˜ï¼š128 GB
æ˜¾å¡ï¼šNVIDIA GeForce RTX 4090 Ti 24GB * 1
```
1. **tokenizer è®­ç»ƒ**ï¼š ç°æœ‰`tokenizer`è®­ç»ƒåº“å­˜åœ¨å¤§è¯­æ–™æ—¶å­˜åœ¨OOMé—®é¢˜ï¼ŒåŠ è½½1000ä¸‡æ¡æ•°æ®ï¼Œå¤§çº¦éœ€è¦100GBå†…å­˜ï¼Œå¯ä»¥æ ¹æ®ç¡¬ä»¶æƒ…å†µï¼Œé€‰å–åˆé€‚æ•°é‡çš„æ•°æ®è¿›è¡Œè®­ç»ƒã€‚

2. **Text-to-Text é¢„è®­ç»ƒ**ï¼šå­¦ä¹ ç‡ä¸º`1e-4`åˆ°`5e-3`çš„åŠ¨æ€å­¦ä¹ ç‡ï¼Œé¢„è®­ç»ƒæ—¶é—´ä¸º8å¤©ã€‚è®­ç»ƒæŸå¤±ï¼š 

![traing loss](img/train_loss.png) 

3. **promptç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰**ï¼šä½¿ç”¨`belle`æŒ‡ä»¤è®­ç»ƒæ•°æ®é›†ï¼ˆæŒ‡ä»¤å’Œå›ç­”é•¿åº¦éƒ½åœ¨512ä»¥ä¸‹ï¼‰ï¼Œå­¦ä¹ ç‡ä¸º`1e-7`åˆ°`5e-5`çš„åŠ¨æ€å­¦ä¹ ç‡ï¼Œå¾®è°ƒæ—¶é—´2å¤©ã€‚å¾®è°ƒæŸå¤±ï¼š 
   
![finetune loss](img/sft_loss.png) 

1. **dpoç›´æ¥åå¥½ä¼˜åŒ–**ï¼šæ•°æ®é›†[alpaca-gpt4-data-zh](https://huggingface.co/datasets/c-s-ale/alpaca-gpt4-data-zh)ä½œä¸º`chosen`æ–‡æœ¬ï¼Œä½¿ç”¨æ­¥éª¤`2`ä¸­SFTæ¨¡å‹å¯¹æ•°æ®é›†ä¸­çš„promptåš`generate`ï¼Œå¾—åˆ°`rejected`æ–‡æœ¬ï¼Œdpoå…¨é‡åå¥½ä¼˜åŒ–ï¼Œå­¦ä¹ ç‡`le-5`ï¼ŒåŠç²¾åº¦`fp16`,å…±`2`ä¸ª`epoch`ï¼Œè€—æ—¶3hã€‚dpoæŸå¤±ï¼š 
 
![dpo loss](img/dpo_loss.png) 

## 2.4 å¯¹è¯æ•ˆæœå±•ç¤º
### 2.4.1 stream chat
é»˜è®¤ä½¿ç”¨`huggingface transformers`çš„ `TextIteratorStreamer`å®ç°æµå¼å¯¹è¯ï¼Œåªæ”¯æŒ`greedy search`ï¼Œå¦‚æœéœ€è¦`beam sample`ç­‰å…¶ä»–ç”Ÿæˆæ–¹å¼ï¼Œè¯·å°†`cli_demo.py`çš„`stream_chat`å‚æ•°ä¿®æ”¹ä¸º`False`ã€‚
![](./img/stream_chat.gif)

### 2.4.2 å¯¹è¯å±•ç¤º
![](./img/show1.png)

å­˜åœ¨é—®é¢˜ï¼šé¢„è®­ç»ƒæ•°æ®é›†åªæœ‰600å¤šä¸‡ï¼Œæ¨¡å‹å‚æ•°ä¹Ÿä»…0.2Bï¼Œä¼šæœ‰ç­”éæ‰€é—®ã€åºŸè¯ç”Ÿæˆå™¨çš„æƒ…å†µã€‚

# ä¸‰ã€ğŸ“‘ä½¿ç”¨è¯´æ˜

## 3.1 å¿«é€Ÿå¼€å§‹ï¼š
```python
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch

model_id = 'charent/ChatLM-mini-Chinese'
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForSeq2SeqLM.from_pretrained(model_id, trust_remote_code=True).to(device)

txt = 'å¦‚ä½•è¯„ä»·Appleè¿™å®¶å…¬å¸ï¼Ÿ'

encode_ids = tokenizer([txt])
input_ids, attention_mask = torch.LongTensor(encode_ids['input_ids']), torch.LongTensor(encode_ids['attention_mask'])

outs = model.my_generate(
    input_ids=input_ids.to(device),
    attention_mask=attention_mask.to(device),
    max_seq_len=256,
    search_type='beam',
)

outs_txt = tokenizer.batch_decode(outs.cpu().numpy(), skip_special_tokens=True, clean_up_tokenization_spaces=True)
print(outs_txt[0])
```
```txt
Appleæ˜¯ä¸€å®¶ä¸“æ³¨äºè®¾è®¡å’Œç”¨æˆ·ä½“éªŒçš„å…¬å¸ï¼Œå…¶äº§å“åœ¨è®¾è®¡ä¸Šæ³¨é‡ç®€çº¦ã€æµç•…å’ŒåŠŸèƒ½æ€§ï¼Œè€Œåœ¨ç”¨æˆ·ä½“éªŒæ–¹é¢åˆ™æ³¨é‡ç”¨æˆ·çš„åé¦ˆå’Œä½¿ç”¨ä½“éªŒã€‚ä½œä¸ºä¸€å®¶é¢†å…ˆçš„ç§‘æŠ€å…¬å¸ï¼Œè‹¹æœå…¬å¸ä¸€ç›´è‡´åŠ›äºä¸ºç”¨æˆ·æä¾›æœ€ä¼˜è´¨çš„äº§å“å’ŒæœåŠ¡ï¼Œä¸æ–­æ¨é™ˆå‡ºæ–°ï¼Œä¸æ–­åˆ›æ–°å’Œæ”¹è¿›ï¼Œä»¥æ»¡è¶³ä¸æ–­å˜åŒ–çš„å¸‚åœºéœ€æ±‚ã€‚
åœ¨iPhoneã€iPadå’ŒMacç­‰äº§å“ä¸Šï¼Œè‹¹æœå…¬å¸ä¸€ç›´ä¿æŒç€åˆ›æ–°çš„æ€åº¦ï¼Œä¸æ–­æ¨å‡ºæ–°çš„åŠŸèƒ½å’Œè®¾è®¡ï¼Œä¸ºç”¨æˆ·æä¾›æ›´å¥½çš„ä½¿ç”¨ä½“éªŒã€‚åœ¨iPadä¸Šæ¨å‡ºçš„iPad Proå’ŒiPod touchç­‰äº§å“ï¼Œä¹Ÿä¸€ç›´ä¿æŒç€ä¼˜ç§€çš„ç”¨æˆ·ä½“éªŒã€‚
æ­¤å¤–ï¼Œè‹¹æœå…¬å¸è¿˜è‡´åŠ›äºå¼€å‘å’Œé”€å”®è½¯ä»¶å’ŒæœåŠ¡ï¼Œä¾‹å¦‚iTunesã€iCloudå’ŒApp Storeç­‰ï¼Œè¿™äº›äº§å“åœ¨å¸‚åœºä¸Šä¹Ÿè·å¾—äº†å¹¿æ³›çš„è®¤å¯å’Œå¥½è¯„ã€‚
æ€»çš„æ¥è¯´ï¼Œè‹¹æœå…¬å¸åœ¨è®¾è®¡ã€ç”¨æˆ·ä½“éªŒå’Œäº§å“åˆ›æ–°æ–¹é¢éƒ½åšå¾—éå¸¸å‡ºè‰²ï¼Œä¸ºç”¨æˆ·å¸¦æ¥äº†è®¸å¤šä¾¿åˆ©å’ŒæƒŠå–œã€‚

```

## 3.2 ä»å…‹éš†ä»“åº“ä»£ç å¼€å§‹

æœ¬é¡¹ç›®æ¨¡å‹ä¸º`TextToText`æ¨¡å‹ï¼Œåœ¨é¢„è®­ç»ƒé˜¶æ®µã€SFTé˜¶æ®µã€RLFHé˜¶æ®µçš„`prompt`ã€`response`ç­‰å­—æ®µï¼Œè¯·åŠ¡å¿…åŠ ä¸Š`[EOS]`å¥å­ç»“æŸæ ‡è®°ã€‚    

### 3.2.1 å…‹éš†é¡¹ç›®ï¼š
```bash
git clone --depth 1 https://github.com/paineliu/SCCLM.git

cd SCCLM
```
### 3.2.2 å®‰è£…ä¾èµ– 

æœ¬é¡¹ç›®æ¨èä½¿ç”¨`python 3.11`ã€‚  

pipå®‰è£…ï¼š
```bash
pip install -r ./requirements.txt
``` 
condaå®‰è£…ï¼š
```bash
conda install --yes --file ./requirements.txt
```

### 3.2.3 ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹åŠæ¨¡å‹é…ç½®æ–‡ä»¶

ç”¨`git`å‘½ä»¤ä»`Hugging Face Hub`ä¸‹è½½æ¨¡å‹æƒé‡åŠé…ç½®æ–‡ä»¶ï¼Œéœ€è¦å…ˆå®‰è£…[Git LFS](https://docs.github.com/zh/repositories/working-with-files/managing-large-files/installing-git-large-file-storage)ï¼Œç„¶åè¿è¡Œ: 

```bash 
# ä½¿ç”¨gitå‘½ä»¤ä¸‹è½½huggingfaceæ¨¡å‹ï¼Œå…ˆå®‰è£…[Git LFS]ï¼Œå¦åˆ™ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶ä¸å¯ç”¨
git clone --depth 1 https://huggingface.co/charent/ChatLM-mini-Chinese

mv ChatLM-mini-Chinese model_save
```

ä¹Ÿå¯ä»¥ç›´æ¥ä»`Hugging Face Hub`ä»“åº“[ChatLM-Chinese-0.2B](https://huggingface.co/charent/ChatLM-mini-Chinese)æ‰‹å·¥ä¸‹è½½ï¼Œå°†ä¸‹è½½çš„æ–‡ä»¶ç§»åŠ¨åˆ°`model_save`ç›®å½•ä¸‹å³å¯ã€‚

## 3.3 Tokenizerè®­ç»ƒ

åŸæœ¬æ‰“ç®—ç›´æ¥ç”¨ç°æˆçš„`tokenizer`åº“è®­ç»ƒçš„ï¼ˆå¦‚`sentencepiece`ï¼‰ï¼Œä½†æ˜¯æ•°æ®é›†ä¸€å¤§å°±å®¹æ˜“OOMã€‚å¦å¤–é¢„è®­ç»ƒæ•°æ®é›†å„ä¸ªé¢†åŸŸçš„è¯­æ–™ä¸å¹³è¡¡ï¼Œä¼šäº§ç”Ÿå¾ˆå¤šä¸å¿…è¦çš„åˆå¹¶ã€‚æœ€åä½¿ç”¨`jieba`åˆ†è¯å¯¹æ‰€æœ‰çš„é¢„è®­ç»ƒè¯­æ–™åˆ‡è¯åç»Ÿè®¡è¯é¢‘ï¼Œåªä¿ç•™å‡ºç°1500æ¬¡ä»¥ä¸Šçš„å­—ã€è¯ï¼Œå‚ç…§`PreTrainedTokenizerFast`çš„`BPE model`çš„ä¿å­˜æ ¼å¼ï¼Œæ„é€ `tokenzier`ï¼Œæœ€åè½¬æ¢ä¸º`PreTrainedTokenizerFast`ã€‚æ ¸å¿ƒä»£ç å¦‚ä¸‹ï¼Œè¯¦ç»†çš„å¤„ç†è¿‡ç¨‹è§`utils/train_tokenizer.py`ã€‚

```python
# æ„é€ mergeæ•°ç»„
words_merge_list = []
for word in words_dict.keys():
    n = len(word)
    if n >= 2:
        # a, båˆ‡åˆ†12345ç¤ºä¾‹ï¼š 1 2345,  12 345,   123 45,   1234 5
        for i in range(1, n):
            a, b = ''.join(word[0: i]), ''.join(word[i: ])

            if a in words_dict and b in words_dict:
                words_merge_list.append((a, b))
```
æœ¬é¡¹ç›®è¿˜æä¾›äº†ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è‡ªå¸¦çš„`tokenizer`æ ¹æ®è‡ªå·±çš„è¯­æ–™é‡æ–°è®­ç»ƒ`tokenizer`çš„ä¾‹å­ï¼Œè§`train_tokenizer.ipynb`ã€‚æ³¨æ„ï¼Œé‡æ–°è®­ç»ƒ`tokenizer`åï¼Œé¢„è®­ç»ƒæ¨¡å‹çš„æƒé‡å°†æ— æ³•ä½¿ç”¨ï¼Œéœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹æƒé‡ï¼Œå› ä¸º`token`å¯¹åº”çš„`id`å˜äº†ã€‚

## 3.4 Text-to-Text é¢„è®­ç»ƒ 

1. é¢„è®­ç»ƒæ•°æ®é›†ç¤ºä¾‹

   
2. jupyter-lab æˆ–è€… jupyter notebook:  

    è§æ–‡ä»¶`train.ipynb`ï¼Œæ¨èä½¿ç”¨jupyter-labï¼Œé¿å…è€ƒè™‘ä¸æœåŠ¡å™¨æ–­å¼€åç»ˆç«¯è¿›ç¨‹è¢«æ€çš„æƒ…å†µã€‚ 

3. æ§åˆ¶å°ï¼š 

    æ§åˆ¶å°è®­ç»ƒéœ€è¦è€ƒè™‘è¿æ¥æ–­å¼€åè¿›ç¨‹è¢«æ€çš„ï¼Œæ¨èä½¿ç”¨è¿›ç¨‹å®ˆæŠ¤å·¥å…·`Supervisor`æˆ–è€…`screen`å»ºç«‹è¿æ¥ä¼šè¯ã€‚

    é¦–å…ˆè¦é…ç½®`accelerate`ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œ æ ¹æ®æç¤ºé€‰æ‹©å³å¯ï¼Œå‚è€ƒ`accelerate.yaml`ï¼Œ*æ³¨æ„ï¼šDeepSpeedåœ¨Windowså®‰è£…æ¯”è¾ƒéº»çƒ¦*ã€‚
    ```bash
    accelerate config
    ```

    å¼€å§‹è®­ç»ƒï¼Œå¦‚æœè¦ä½¿ç”¨å·¥ç¨‹æä¾›çš„é…ç½®è¯·åœ¨ä¸‹é¢çš„å‘½ä»¤`accelerate launch`ååŠ ä¸Šå‚æ•°`--config_file ./accelerate.yaml`ï¼Œ*è¯¥é…ç½®æŒ‰ç…§å•æœº2xGPUé…ç½®ã€‚* 

    *é¢„è®­ç»ƒæœ‰ä¸¤ä¸ªè„šæœ¬ï¼Œæœ¬é¡¹ç›®å®ç°çš„trainerå¯¹åº”`train.py`ï¼Œhuggingfaceå®ç°çš„trainerå¯¹åº”`pre_train.py`ï¼Œç”¨å“ªä¸ªéƒ½å¯ä»¥ï¼Œæ•ˆæœä¸€è‡´ã€‚æœ¬é¡¹ç›®å®ç°çš„trainerè®­ç»ƒä¿¡æ¯å±•ç¤ºæ›´ç¾è§‚ã€æ›´å®¹æ˜“ä¿®æ”¹è®­ç»ƒç»†èŠ‚ï¼ˆå¦‚æŸå¤±å‡½æ•°ï¼Œæ—¥å¿—è®°å½•ç­‰ï¼‰ï¼Œå‡æ”¯æŒæ–­ç‚¹ç»§ç»­è®­ç»ƒï¼Œæœ¬é¡¹ç›®å®ç°çš„traineræ”¯æŒåœ¨ä»»æ„ä½ç½®æ–­ç‚¹åç»§ç»­è®­ç»ƒï¼ŒæŒ‰`ctrl+c`é€€å‡ºè„šæœ¬æ—¶ä¼šä¿å­˜æ–­ç‚¹ä¿¡æ¯ã€‚* 

    å•æœºå•å¡ï¼š
    ```bash
    # æœ¬é¡¹ç›®å®ç°çš„trainer
    accelerate launch ./train.py train

    # æˆ–è€…ä½¿ç”¨ huggingface trainer
    python ./chatbot/train.py
    ```

    å•æœºå¤šå¡ï¼š
    `2`ä¸ºæ˜¾å¡æ•°é‡ï¼Œè¯·æ ¹æ®è‡ªå·±çš„å®é™…æƒ…å†µä¿®æ”¹ã€‚
    ```bash
    # æœ¬é¡¹ç›®å®ç°çš„trainer
    accelerate launch --multi_gpu --num_processes 2 ./train.py train

    # æˆ–è€…ä½¿ç”¨ huggingface trainer
    accelerate launch --multi_gpu --num_processes 2 pre_train.py
    ```

    ä»æ–­ç‚¹å¤„ç»§ç»­è®­ç»ƒï¼š
    ```bash
    # æœ¬é¡¹ç›®å®ç°çš„trainer
    accelerate launch --multi_gpu --num_processes 2 ./train.py train --is_keep_training=True

    # æˆ–è€…ä½¿ç”¨ huggingface trainer
    # éœ€è¦åœ¨`pre_train.py`ä¸­çš„`train`å‡½æ•°æ·»åŠ `resume_from_checkpoint=True`
    accelerate launch --multi_gpu --num_processes 2 pre_train.py
    ```

## 3.5 SFTå¾®è°ƒ 
å¾®è°ƒç»†èŠ‚è§`model/trainer.py`ä¸‹çš„`train`æ–¹æ³•, `is_finetune`è®¾ç½®ä¸º`True`æ—¶ï¼Œå°†è¿›è¡Œå¾®è°ƒï¼Œå¾®è°ƒé»˜è®¤ä¼šå†»ç»“embeddingå±‚å’Œencoderå±‚ï¼Œåªè®­ç»ƒdecoderå±‚ã€‚å¦‚éœ€è¦å†»ç»“å…¶ä»–å‚æ•°ï¼Œè¯·è‡ªè¡Œè°ƒæ•´ä»£ç ã€‚ 

è¿è¡ŒSFTå¾®è°ƒï¼š
``` bash
# æœ¬é¡¹ç›®å®ç°çš„trainerï¼Œ æ·»åŠ å‚æ•°`--is_finetune=True`å³å¯, å‚æ•°`--is_keep_training=True`å¯ä»ä»»æ„æ–­ç‚¹å¤„ç»§ç»­è®­ç»ƒ
accelerate launch --multi_gpu --num_processes 2 ./train.py --is_finetune=True

# æˆ–è€…ä½¿ç”¨ huggingface trainer, å¤šGPUè¯·ç”¨accelerate launch --multi_gpu --num_processes gpuä¸ªæ•° sft_train.py
python sft_train.py
```

## 3.6 RLHFï¼ˆå¼ºåŒ–å­¦ä¹ äººç±»åé¦ˆä¼˜åŒ–æ–¹æ³•ï¼‰

åå¥½æ–¹æ³•è¿™é‡Œä»‹ç»å¸¸è§çš„ä¸¤ç§ï¼šPPOå’ŒDPOï¼Œå…·ä½“å®ç°è¯·è‡ªè¡Œæœç´¢è®ºæ–‡åŠåšå®¢ã€‚

1.  PPOæ–¹æ³•ï¼ˆè¿‘ä¼¼åå¥½ä¼˜åŒ–,Proximal Policy Optimizationï¼‰  
    æ­¥éª¤1ï¼šä½¿ç”¨å¾®è°ƒæ•°æ®é›†åšæœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼Œ Supervised Finetuningï¼‰ã€‚   
    æ­¥éª¤2ï¼šä½¿ç”¨åå¥½æ•°æ®é›†ï¼ˆä¸€ä¸ªpromptè‡³å°‘åŒ…å«2ä¸ªå›å¤ï¼Œä¸€ä¸ªæƒ³è¦çš„å›å¤ï¼Œä¸€ä¸ªä¸æƒ³è¦çš„å›å¤ã€‚å¤šä¸ªå›å¤å¯ä»¥æŒ‰ç…§åˆ†æ•°æ’åºï¼Œæœ€æƒ³è¦çš„åˆ†æ•°æœ€é«˜ï¼‰è®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼ˆRMï¼Œ Reward Modelï¼‰ã€‚å¯ä½¿ç”¨`peft`åº“å¿«é€Ÿæ­å»ºLoraå¥–åŠ±æ¨¡å‹ã€‚   
    æ­¥éª¤3ï¼šåˆ©ç”¨RMå¯¹SFTæ¨¡å‹è¿›è¡Œæœ‰ç›‘ç£PPOè®­ç»ƒï¼Œä½¿å¾—æ¨¡å‹æ»¡è¶³åå¥½ã€‚   

2.  ä½¿ç”¨DPOï¼ˆç›´æ¥åå¥½ä¼˜åŒ–ï¼ŒDirect Preference Optimizationï¼‰å¾®è°ƒï¼ˆ**æœ¬é¡¹ç›®é‡‡ç”¨DPOå¾®è°ƒæ–¹æ³•ï¼Œæ¯”è¾ƒèŠ‚çœæ˜¾å­˜**ï¼‰
    åœ¨è·å¾—SFTæ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œæ— éœ€è®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œå–å¾—æ­£å‘å›ç­”ï¼ˆchosenï¼‰å’Œè´Ÿå‘å›ç­”ï¼ˆrejectedï¼‰å³å¯å¼€å§‹å¾®è°ƒã€‚
    
    dpoæ•°æ®é›†å¤„ç†è¿‡ç¨‹è§`utils/dpo_data_process.py`ã€‚
    


è¿è¡Œåå¥½ä¼˜åŒ–ï¼š
``` bash
#  å¤šGPUè¯·ç”¨accelerate launch --multi_gpu --num_processes gpuä¸ªæ•° dpo_train.py
python dpo_train.py
```

## 3.7 æ¨ç† 
ç¡®ä¿`model_save`ç›®å½•ä¸‹æœ‰ä»¥ä¸‹æ–‡ä»¶ï¼Œè¿™äº›æ–‡ä»¶éƒ½å¯ä»¥åœ¨`Hugging Face Hub`ä»“åº“[ChatLM-Chinese-0.2B](https://huggingface.co/charent/ChatLM-mini-Chinese)ä¸­æ‰¾åˆ°ï¼š
```bash
ChatLM-mini-Chinese
â”œâ”€model_save
|  â”œâ”€config.json
|  â”œâ”€configuration_chat_model.py
|  â”œâ”€generation_config.json
|  â”œâ”€model.safetensors
|  â”œâ”€modeling_chat_model.py
|  â”œâ”€special_tokens_map.json
|  â”œâ”€tokenizer.json
|  â””â”€tokenizer_config.json
```

1. æ§åˆ¶å°è¿è¡Œï¼š
```bash
python cli_demo.py
```

2. APIè°ƒç”¨
```bash
python api_demo.py
```

APIè°ƒç”¨ç¤ºä¾‹ï¼š
```bash
curl --location '127.0.0.1:8812/api/chat' \
--header 'Content-Type: application/json' \
--header 'Authorization: Bearer Bearer' \
--data '{
    "input_txt": "æ„Ÿå†’äº†è¦æ€ä¹ˆåŠ"
}'
```
![api demo](./img/api_example.png)

## 3.8 ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒ

è¿™é‡Œä»¥æ–‡æœ¬ä¸­ä¸‰å…ƒç»„ä¿¡æ¯ä¸ºä¾‹ï¼Œåšä¸‹æ¸¸å¾®è°ƒã€‚è¯¥ä»»åŠ¡çš„ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æŠ½å–æ–¹æ³•è§ä»“åº“[pytorch_IE_model](https://github.com/charent/pytorch_IE_model)ã€‚æŠ½å–å‡ºä¸€æ®µæ–‡æœ¬ä¸­æ‰€æœ‰çš„ä¸‰å…ƒç»„ï¼Œå¦‚å¥å­`ã€Šå†™ç”Ÿéšç¬”ã€‹æ˜¯å†¶é‡‘å·¥ä¸š2006å¹´å‡ºç‰ˆçš„å›¾ä¹¦ï¼Œä½œè€…æ˜¯å¼ æ¥äº®`ï¼ŒæŠ½å–å‡ºä¸‰å…ƒç»„`(å†™ç”Ÿéšç¬”,ä½œè€…,å¼ æ¥äº®)`å’Œ`(å†™ç”Ÿéšç¬”,å‡ºç‰ˆç¤¾,å†¶é‡‘å·¥ä¸š)`ã€‚ 

åŸå§‹æ•°æ®é›†ä¸ºï¼š[ç™¾åº¦ä¸‰å…ƒç»„æŠ½å–æ•°æ®é›†](https://aistudio.baidu.com/datasetdetail/11384)ã€‚åŠ å·¥å¾—åˆ°çš„å¾®è°ƒæ•°æ®é›†æ ¼å¼ç¤ºä¾‹ï¼š
```json
{
    "prompt": "è¯·æŠ½å–å‡ºç»™å®šå¥å­ä¸­çš„æ‰€æœ‰ä¸‰å…ƒç»„ã€‚ç»™å®šå¥å­ï¼šã€Šå®¶ä¹¡çš„æœˆäº®ã€‹æ˜¯å®‹é›ªè±æ¼”å”±çš„ä¸€é¦–æ­Œæ›²ï¼Œæ‰€å±ä¸“è¾‘æ˜¯ã€Šä¹…è¿çš„å“¥ä»¬ã€‹",
    "response": "[(å®¶ä¹¡çš„æœˆäº®,æ­Œæ‰‹,å®‹é›ªè±),(å®¶ä¹¡çš„æœˆäº®,æ‰€å±ä¸“è¾‘,ä¹…è¿çš„å“¥ä»¬)]"
}
```

å¯ä»¥ç›´æ¥ä½¿ç”¨`sft_train.py`è„šæœ¬è¿›è¡Œå¾®è°ƒï¼Œè„šæœ¬[finetune_IE_task.ipynb](./finetune_examples/info_extract/finetune_IE_task.ipynb)é‡Œé¢åŒ…å«è¯¦ç»†çš„è§£ç è¿‡ç¨‹ã€‚è®­ç»ƒæ•°æ®é›†çº¦`17000`æ¡ï¼Œå­¦ä¹ ç‡`5e-5`ï¼Œè®­ç»ƒepoch`5`ã€‚å¾®è°ƒåå…¶ä»–ä»»åŠ¡çš„å¯¹è¯èƒ½åŠ›ä¹Ÿæ²¡æœ‰æ¶ˆå¤±ã€‚

![ä¿¡æ¯æŠ½å–ä»»åŠ¡å¾®è°ƒåçš„å¯¹è¯èƒ½åŠ›](./img/ie_task_chat.png)

å¾®è°ƒæ•ˆæœï¼š
å°†`ç™¾åº¦ä¸‰å…ƒç»„æŠ½å–æ•°æ®é›†`å…¬å¼€çš„`dev`æ•°æ®é›†ä½œä¸ºæµ‹è¯•é›†ï¼Œå¯¹æ¯”ä¼ ç»Ÿæ–¹æ³•[pytorch_IE_model](https://github.com/charent/pytorch_IE_model)ã€‚

|          æ¨¡å‹            |   F1åˆ†æ•°  |  ç²¾ç¡®ç‡P |  å¬å›ç‡R |
|          :---            |  :----:  |    :---:  |  :---:   |
| ChatLM-Chinese-0.2Bå¾®è°ƒ  |   0.74    |  0.75   |  0.73    |
| ChatLM-Chinese-0.2Bæ— é¢„è®­ç»ƒ| 0.51    |   0.53   | 0.49    |
| ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ–¹æ³•          |   0.80    |  0.79   |  80.1    |

å¤‡æ³¨ï¼š`ChatLM-Chinese-0.2Bæ— é¢„è®­ç»ƒ`æŒ‡ç›´æ¥åˆå§‹åŒ–éšæœºå‚æ•°ï¼Œå¼€å§‹è®­ç»ƒï¼Œå­¦ä¹ ç‡`1e-4`ï¼Œå…¶ä»–å‚æ•°å’Œå¾®è°ƒä¸€è‡´ã€‚

# å››ã€ğŸ“å¼•ç”¨
å¦‚æœä½ è§‰å¾—æœ¬é¡¹ç›®å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæ¬¢è¿å¼•ç”¨ã€‚
```conf
@misc{Charent2023,
    author={Charent Chen},
    title={A small chinese chat language model with 0.2B parameters base on T5},
    year={2023},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/charent/ChatLM-mini-Chinese}},
}
```

# äº”ã€ğŸ¤”å…¶ä»–äº‹é¡¹
æœ¬é¡¹ç›®ä¸æ‰¿æ‹…å¼€æºæ¨¡å‹å’Œä»£ç å¯¼è‡´çš„æ•°æ®å®‰å…¨ã€èˆ†æƒ…é£é™©æˆ–å‘ç”Ÿä»»ä½•æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­ã€ä¸å½“åˆ©ç”¨è€Œäº§ç”Ÿçš„é£é™©å’Œè´£ä»»ã€‚

é¡¹ç›®ä¸»è¦å‚è€ƒäº†ChatLM-mini-Chineseé¡¹ç›®ï¼š
```conf
@misc{Charent2023,
    author={Charent Chen},
    title={A small chinese chat language model with 0.2B parameters base on T5},
    year={2023},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/charent/ChatLM-mini-Chinese}},
}
```

<!-- # æç¤º
```bash
# å¯¼å‡ºé¡¹ç›®ä¾èµ–çš„åŒ…ï¼š
pipreqs --encoding "utf-8" --force
``` -->

